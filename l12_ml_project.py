# -*- coding: utf-8 -*-
"""l12-ml-project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GW6Uw4yQ2HDsd-pIYSKehD5XhDqnEHIO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.neighbors import KNeighborsClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.decomposition import PCA
import seaborn as sn
from imblearn.over_sampling import RandomOverSampler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
import time
import os

import warnings
warnings.filterwarnings('ignore')

train = pd.read_csv('/kaggle/input/l12data/train.csv')
valid = pd.read_csv('/kaggle/input/l12data/valid.csv')
test = pd.read_csv('/kaggle/input/l12data/test.csv')

train.shape

svm = SVC(kernel='linear')
def svm_classifier(X_train, Y_train, X_val, Y_val):
    svm.fit(X_train, Y_train)

    y_pred = svm.predict(X_val)

    accuracy = accuracy_score(Y_val, y_pred)
    return accuracy

knn = KNeighborsClassifier(n_neighbors=1)
def knn_classifier(X_train, Y_train, X_val, Y_val):

    knn.fit(np.array(X_train), Y_train)

    y_pred = knn.predict(np.array(X_val))

    accuracy = accuracy_score(Y_val, y_pred)
    return accuracy

logreg = LogisticRegression()
def logistic_regression_classifier(X_train, Y_train, X_val, Y_val):

    logreg.fit(X_train, Y_train)

    y_pred = logreg.predict(X_val)

    accuracy = accuracy_score(Y_val, y_pred)
    return accuracy

catboost = CatBoostClassifier()

def catboost_classifier(X_train, Y_train, X_val, Y_val):

    catboost.fit(X_train, Y_train)

    y_pred = catboost.predict(X_val)

    accuracy = accuracy_score(Y_val, y_pred)
    return accuracy

def id_highly_correlated_features(dataset, threshold):
    corr_matrix = dataset.corr().abs()
    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))
    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]
    return set(to_drop)

def id_weekly_correlated_features_with_label(dataset, label, threshold = 0.01):
    for label_ in train.iloc[:, -4:]:
        if label_ != label:
            dataset = dataset.drop(label_, axis=1)  # remove other targets from the dataset
    corr_matrix = dataset.corr().abs()
    weak_corr_features = corr_matrix[corr_matrix[label] < threshold].index.tolist()
    if label in weak_corr_features:
        weak_corr_features.remove(label)
    return weak_corr_features

"""# Label 1"""

label_1_train = train.copy()
label_1_valid = valid.copy()
label_1_test = test.copy()

label_1_train = label_1_train.dropna(subset=['label_1'])
label_1_valid = label_1_valid.dropna(subset=['label_1'])

label_1_test.head()

X_train = label_1_train.iloc[:, :-4]
y_train = label_1_train.iloc[:, -4:]
X_val = label_1_valid.iloc[:, :-4]
y_val = label_1_valid.iloc[:, -4:]
X_test = label_1_test.iloc[:, 1:]

plt.figure(figsize=(18, 6))
sn.countplot(data=y_train, x='label_1', palette='Set2')
plt.title('Distribution of label_1 Classes')
plt.xlabel('label_1')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

X_train_scaled.shape

pca = PCA(n_components=0.99, svd_solver = 'full')
X_train_pca = pca.fit_transform(X_train)
X_val_pca = pca.transform(X_val)
X_test_pca = pca.transform(X_test)

X_train_pca.shape

# # defining parameter range
# param_grid = {'depth': [6, 8],
#               'learning_rate' : [0.01, 0.05, 0.1],
#               'iterations': [100]}

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(task_type="GPU")

# # Create GridSearchCV object
# grid = GridSearchCV(cb, param_grid, cv=3, verbose=2)

# # fitting the model for grid search
# grid.fit(X_train_pca, y_train['label_1'])

# # get the best parameters
# grid.best_params_

# # Define parameter range
# param_grid = {'C': [100,1000],
#               'gamma': [ 0.1, 0.01],
#               'kernel': ['rbf']}

# # Create a SVM object
# svc = SVC()

# # Create GridSearchCV object
# grid = GridSearchCV(svc, param_grid, cv=3, verbose=2)

# # Fit the model for grid search
# grid.fit(X_train_pca, y_train['label_1'])

# # Get the best parameters
# grid.best_params_

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(depth=6, learning_rate=0.1, iterations=100,task_type="GPU")

# # Perform cross-validation and compute the mean score
# mean_score = cross_val_score(cb, X_train_pca, y_train['label_1'], cv=3).mean()

cross_val_score(SVC(C=1000, gamma=0.01, kernel='rbf'), X_train_pca, y_train['label_1'], cv=3).mean()

best_model_label_1 = SVC(C=1000, gamma=0.01, kernel='rbf', probability=True)
best_model_label_1.fit(X_train_pca, y_train['label_1'])

label_1_pred_after = best_model_label_1.predict(np.array(X_test_pca))

"""# Label 2"""

label_2_train = train.copy()
label_2_valid = valid.copy()
label_2_test = test.copy()
label_2_test.head()

label_2_train = label_2_train.dropna(subset=['label_2'])
label_2_valid = label_2_valid.dropna(subset=['label_2'])

X_train = label_2_train.iloc[:, :-4]
y_train = label_2_train.iloc[:, -3:]
X_val = label_2_valid.iloc[:, :-4]
y_val = label_2_valid.iloc[:, -3:]
X_test = label_2_test.iloc[:, 1:]

X_test.head()

plt.figure(figsize=(18, 6))
ax = sn.countplot(x=y_train['label_2'], color='teal')

for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=9, color='black')

ros = RandomOverSampler(random_state=0)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train['label_2'])

plt.figure(figsize=(18, 6))
ax = sn.countplot(x=y_train_resampled, color='teal')

for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=9, color='black')

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_resampled)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

X_train_scaled.shape

# accuracy with all the features
#svm
start_time = time.time()
accuracy = svm_classifier(X_train_scaled, y_train_resampled, X_val, y_val['label_2'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#knn
start_time = time.time()
accuracy = knn_classifier(X_train_scaled, y_train_resampled, X_val, y_val['label_2'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#logistic_regression_classifier
start_time = time.time()
accuracy = logistic_regression_classifier(X_train, y_train['label_2'], X_val, y_val['label_2'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

pca = PCA(n_components=0.98, svd_solver = 'full')
X_train_pca = pca.fit_transform(X_train_scaled)
X_val_pca = pca.transform(X_val)
X_test_pca = pca.transform(X_test)

X_train_pca.shape

# # defining parameter range
# param_grid = {'depth': [6, 8],
#               'learning_rate' : [0.01, 0.05, 0.1],
#               'iterations': [100]}

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(task_type="GPU")

# # Create GridSearchCV object
# grid = GridSearchCV(cb, param_grid, cv=3, verbose=2)

# # fitting the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # get the best parameters
# grid.best_params_

# # Define parameter range
# param_grid = {'C': [100,1000],
#               'gamma': [ 0.1, 0.01],
#               'kernel': ['rbf']}

# # Create a SVM object
# svc = SVC()

# # Create GridSearchCV object
# grid = GridSearchCV(svc, param_grid, cv=3, verbose=2)

# # Fit the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # Get the best parameters
# grid.best_params_

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(depth=8, learning_rate=0.1, iterations=100,task_type="GPU")

# # Perform cross-validation and compute the mean score
# cross_val_score(cb, X_train_pca, y_train_resampled, cv=3).mean()

# best_model_label_2 = CatBoostClassifier(depth=8, learning_rate=0.1, iterations=100,task_type="GPU")
# best_model_label_2.fit(X_train_pca, y_train_resampled)

cross_val_score(SVC(C=1000, gamma=0.01, kernel='rbf'), X_train_pca, y_train_resampled, cv=3).mean()

best_model_label_2 = SVC(C=1000, gamma=0.01, kernel='rbf', probability=True)
best_model_label_2.fit(X_train_pca, y_train_resampled)

label_2_pred_after = best_model_label_2.predict(np.array(X_test_pca))

"""# Label 3"""

label_3_train = train.copy()
label_3_valid = valid.copy()
label_3_test = test.copy()

label_3_train = label_3_train.dropna(subset=['label_3'])
label_3_valid = label_3_valid.dropna(subset=['label_3'])

X_train = label_3_train.iloc[:, :-4]
y_train = label_3_train.iloc[:, -2:]
X_val = label_3_valid.iloc[:, :-4]
y_val = label_3_valid.iloc[:, -2:]
X_test = label_3_test.iloc[:, 1:]

plt.figure(figsize=(18, 6))
sn.histplot(data=y_train, x='label_3', bins=20, kde=False)

ros = RandomOverSampler(random_state=0, sampling_strategy=0.75)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train['label_3'])

y_train_resampled

ax = sn.countplot(x=y_train_resampled)

for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=9, color='black')

# accuracy with all the features
#svm
start_time = time.time()
accuracy = svm_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_3'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#knn
start_time = time.time()
accuracy = knn_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_3'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#logistic_regression_classifier
start_time = time.time()
accuracy = logistic_regression_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_3'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
# catboost_classifier
start_time = time.time()
accuracy = catboost_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_3'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_resampled)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

pca = PCA(n_components=0.98, svd_solver = 'full')
X_train_pca = pca.fit_transform(X_train_scaled)
X_val_pca = pca.transform(X_val)
X_test_pca = pca.transform(X_test)

X_train_pca.shape

# # defining parameter range
# param_grid = {'depth': [6, 8],
#               'learning_rate' : [0.01, 0.05, 0.1],
#               'iterations': [100]}

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(task_type="GPU")

# # Create GridSearchCV object
# grid = GridSearchCV(cb, param_grid, cv=3, verbose=2)

# # fitting the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # get the best parameters
# grid.best_params_

# # Define parameter range
# param_grid = {'C': [100,1000],
#               'gamma': [ 0.1, 0.01],
#               'kernel': ['rbf']}

# # Create a SVM object
# svc = SVC()

# # Create GridSearchCV object
# grid = GridSearchCV(svc, param_grid, cv=3, verbose=2)

# # Fit the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # Get the best parameters
# grid.best_params_

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(depth=8, learning_rate=0.1, iterations=100,task_type="GPU")

# # Perform cross-validation and compute the mean score
# cross_val_score(cb, X_train_pca, y_train_resampled, cv=3).mean()

cross_val_score(SVC(C=1000, gamma=0.01, kernel='rbf'), X_train_pca, y_train_resampled, cv=3).mean()

best_model_label_3 = SVC(C=1000, gamma=0.01, kernel='rbf')
best_model_label_3.fit(X_train_pca, y_train_resampled)

label_3_pred_after = best_model_label_3.predict(np.array(X_test_pca))

"""# Label 4"""

label_4_train = train.copy()
label_4_valid = valid.copy()
label_4_test = test.copy()

label_4_train = label_4_train.dropna(subset=['label_4'])
label_4_valid = label_4_valid.dropna(subset=['label_4'])

X_train = label_4_train.iloc[:, :-4]
y_train = label_4_train.iloc[:, -1:]
X_val = label_4_valid.iloc[:, :-4]
y_val = label_4_valid.iloc[:, -1:]
X_test = label_4_test.iloc[:, 1:]

plt.figure(figsize=(18, 6))
sn.histplot(data=y_train, x='label_4', bins=20, kde=False)

plt.figure(figsize=(18, 6))
ax = sn.countplot(x=y_train['label_4'], color='teal')

for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=9, color='black')

# accuracy with all the features
#knn
start_time = time.time()
accuracy = knn_classifier(X_train, y_train, X_val, y_val['label_4'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

ros = RandomOverSampler(random_state=0)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train['label_4'])

plt.figure(figsize=(18, 6))
ax = sn.countplot(x=y_train_resampled, color='teal')

for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=9, color='black')

scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_resampled)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

pca = PCA(n_components=0.98, svd_solver = 'full')
X_train_pca = pca.fit_transform(X_train_scaled)
X_val_pca = pca.transform(X_val_scaled)
X_test_pca = pca.transform(X_test_scaled)

X_train_pca.shape

# # defining parameter range
# param_grid = {'depth': [6, 8],
#               'learning_rate' : [0.01, 0.05, 0.1],
#               'iterations': [100]}

# # Create a CatBoostClassifier object
# cb = CatBoostClassifier(task_type="GPU")

# # Create GridSearchCV object
# grid = GridSearchCV(cb, param_grid, cv=3, verbose=2)

# # fitting the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # get the best parameters
# grid.best_params_

# # Define parameter range
# param_grid = {'C': [100,1000],
#               'gamma': [ 0.1, 0.01],
#               'kernel': ['rbf']}

# # Create a SVM object
# svc = SVC()

# # Create GridSearchCV object
# grid = GridSearchCV(svc, param_grid, cv=3, verbose=2)

# # Fit the model for grid search
# grid.fit(X_train_pca, y_train_resampled)

# # Get the best parameters
# grid.best_params_

# cb = CatBoostClassifier(depth=8, learning_rate=0.1, iterations=100,task_type="GPU")
# cross_val_score(cb, X_train_pca, y_train_resampled, cv=3).mean()

# accuracy with all the features
#svm
start_time = time.time()
accuracy = svm_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_4'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#knn
start_time = time.time()
accuracy = knn_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_4'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

# accuracy with all the features
#logistic_regression_classifier
start_time = time.time()
accuracy = logistic_regression_classifier(X_train_resampled, y_train_resampled, X_val, y_val['label_4'] )
elapsed_time = time.time() - start_time
print(f"Accuracy: {accuracy * 100:.2f}% in {elapsed_time} secs")

cross_val_score(SVC(C=1000, gamma=0.01, kernel='rbf'), X_train_pca, y_train_resampled, cv=3).mean()

# best_model_label_4 = CatBoostClassifier(depth=8, learning_rate=0.1, iterations=100,task_type="GPU")
# best_model_label_4.fit(X_train_pca, y_train_resampled)

best_model_label_4 = SVC(C=1000, gamma=0.01, kernel='rbf')
best_model_label_4.fit(X_train_pca, y_train_resampled)

label_4_pred_after = best_model_label_4.predict(np.array(X_test_pca))

"""# Kaggle competition output"""

output_df = test[['ID']]
output_df['label_1'] = label_1_pred_after
output_df['label_2'] = label_2_pred_after
output_df['label_3'] = label_3_pred_after
output_df['label_4'] = label_4_pred_after

output_df.head()

output_df.to_csv('predictions_L12_fsvm.csv', index=False)